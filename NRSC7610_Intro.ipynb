{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python (for Systems Neuro)\n",
    "## a guided tour of data analysis with python\n",
    "11 March 2024<br>\n",
    "NRSC 7610 Systems Neuroscience<br>\n",
    "Daniel J Denman<br>\n",
    "University of Colorado Anschutz<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important: this is not meant to be a comprehensive guide. \n",
    "Use the internet! [Python documentation](https://docs.python.org/3.7/tutorial/index.html), [Stack Overflow](https://stackoverflow.com/), Google, Markdown cheatsheets [(e.g. this one)](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) all are your friends.\n",
    "### we're going to cover two things in the introduction here:\n",
    "0. Jupyter notebooks and some pure Python basics\n",
    "1. Importing useful packages for neuroscience analysis [and doing a few things with them]\n",
    "<br>[hot tip: python indexing starts with 0!]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebooks and some pure Python basics\n",
    "#### Here, we are using a Jupyter notebook environment to run a Python kernel\n",
    "##### [for posterity: you've had the option to run the Jupyter locally or on Google colab]\n",
    "##### First, let's get our bearings in a Jupyter notebook<br>\n",
    "In a Jupyter notebook, we can iteratively explore data, do computations, make plots, and define functions and objects.<br>\n",
    "The notebook will contain a mix of code, markdown (a simple way to make formatted text) that might explain what is going on in the code, and outputs. The outputs will be in the form of printed statements and plots.\n",
    "<br>\n",
    "The fundamental unit of the Jupyter notebook is the cell. Here is an empty code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can see the empty brackets on the left; this bracket is empty until the cell is executed\n",
    "- Cells can be \"code\", \"markdown\", or \"raw\". This cell, for example, is a \"markdown cell\". When i execute it (by pressing ```Shift + Enter```), it renders the text I have entered. <br>\n",
    "- In the cell below, a code cell, we will enter some code. To execute it, click on a cell so it has a blue (or other color) box around it, and press ```Shift + Enter```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world! time to do some science\n"
     ]
    }
   ],
   "source": [
    "message = 'hello world! time to do some science' #define a variable. this variable happens to a string, not a number, because we put the value in ''\n",
    "print(message) #print() is a function that is part of core python. it prints text; in the case of notebook, this will appear in the output of this cell, below the cell. print() is very useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the empty brackets on the left of the cell above have now been filled with a number, which is the order in in which the cell was executed. This will forever increment until the  this bracket is empty until the kernel (or Jupyter notebook) is restarted.\n",
    "<br>Also, you'll notice i added some text after a ```#```; this is commented code, which is ignored by the interepreter. you can write whatever you want, but the idea is to note what you did, if it is important/not clear from the syntax\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "So far, this notebook has only the Python kernel at the moment. It can only do basic Python things, like define simple variables and do simple operations:\n",
    "<br>\n",
    "<br>\n",
    "with letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'some letters'\n",
    "name = 'your name'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 12\n",
    "b = 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python has built in variable types. in this case, we have used ```str```, ```int```, and ```float```. \n",
    "<br>```str``` is declared with ```''```\n",
    "<br>```int``` is declared with any number [no decimal point]\n",
    "<br>```float``` is declared with a number with a decimal point\n",
    "<br>\n",
    "<br>now we can do some things with the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(a))\n",
    "print(type(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word + name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here are some other useful standard python variable types:\n",
    "<br>list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_list = []\n",
    "list_of_things = [1, 'a', a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_things = {'key1':a,\n",
    "                  'key2':b,\n",
    "                  'key3':9,\n",
    "                  'someotherkey':group_of_things}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another key concept for Jupyter is the difference between using the keyboard to add code or markdown, and using the keyboard to change the notebook itself. When you are \"in\" a cell, you are adding code or markdown. To jump up a level to add a cell, you need to ```esc``` out of that cell. Now at the noteook level, you can use letters on the keyboard to do thinge like add, delete, copy, paste, etc. cells. To add, press ```a``` (to add above where you are) or ```b``` (to add below). ```c``` for copy, ```x``` for cut, ```v``` for paste. Remember, no ```Shift```s needed. Try adding a cell below this one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These shortcuts can be found over there on the left in menu with a palette, or on the internet. Other important ones: ```dd``` to delete, and ```Enter``` to go down a level and in to the cell you have selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> There are other tricks to notebooks: moving cells, copy/cuttting cells, running all or sets of cells, etc. Demonstrate some."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systems Neuroscience Analysis: \n",
    "## Analyzing time series\n",
    "Almost all of the concepts you will hear about in this course involve measurements of neural activity, usually relative to something an experimenter is controlling or measuring. In NRSC 7610, in various lectures, you will see spikes, Ca2+ transients that reflect spikes, field potentials, electromyographs, maybe others.\n",
    "<br>\n",
    "### a commonality is that this is the quantitative analysis of wiggles. also called time series.\n",
    "<br>\n",
    "<img src=\"https://github.com/danieljdenman/nrsc7610/blob/master/res/wigglefig.png?raw=true\" width=\"450\" height=\"600\" />\n",
    "<br>\n",
    "making measurements from time series is at the heart of systems (and some other) neuroscience. we're going to use a computer to this, because its 2024. it wasn't always like this! we (broadly speaking) used to draw wiggles on paper and measure them with rulers:\n",
    "<br>\n",
    "<img src=\"https://i.ebayimg.com/images/g/bHkAAOSw0lFlS-0t/s-l960.jpg\" width=\"600\" height=\"600\" />\n",
    "\n",
    "<!-- ![strip chart recorder]() -->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using a programming language, in this case python, to systematically work with _**lists of numbers**_, has been fundamental to moving neuroscience. for example, beyond the limits of rulers and strip chart recorders.\n",
    "\n",
    "#### We are going to start with a reduced case of systems neuroscience analysis, to focus a bit more on the coding/analysis in this activity. \n",
    "and because we're early in the course.<br><br>\n",
    "We'll have one neuron's action potential times and the times of stimuli that may (or may not) affect this neuron. <br><br>\n",
    "The nature of the neuron and the stimuli aren't critical for this intro; several lectures will get into greater detail with analysis applications later in the course. <br>\n",
    "<br><br>\n",
    "Choose **_one_** of the below two cells \n",
    "<br><br>1.\n",
    "if you are using Google Colab, run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab the data from the Denman lab, so you have it locally (either in colab or on to your computer)\n",
    "import requests, h5py\n",
    "url = 'https://storage.googleapis.com/denmanlab/M192079_noRawData.nwb'\n",
    "response = requests.get(url)\n",
    "with open(\"/media/M192079_noRawData.nwb\", mode=\"wb\") as file:\n",
    "     file.write(response.content)\n",
    "nwb = h5py.File('/media/M192079_noRawData.nwb') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. if you have the repository locally, run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab the same data, locally from the course repo folder /res\n",
    "import h5py \n",
    "nwb = h5py.File('./res/M192079_noRawData.nwb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we're going to use this data to analyze a time series, in this case a spike train from a neuron<br>\n",
    "our goal will be to plot the peri-event (also called peri-stimulus in some cases) histogram, or PETH (or PSTH). for one cell. like so:<br>\n",
    "<img src=\"https://github.com/danieljdenman/nrsc7610/blob/master/res/output.png?raw=true\" width=\"400\" height=\"300\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to get this goal, we'll grab the spike times (the blue dots in the above figure) from one neuron\n",
    "and the times when some other things happened, to measure relative to these spike times. we will call them `dark_stimulus_times` and `bright_stimulus_times`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "#grab action potentals (spikes) from one cell:\n",
    "spike_times = np.array(nwb['processing']['LGN']['UnitTimes']['263']['times'])\n",
    "\n",
    "#load some stim times\n",
    "dark_stimulus_times = np.array(nwb['stimulus']['presentation']['flash_green']['timestamps'])[1:][::2]\n",
    "bright_stimulus_times = np.array(nwb['stimulus']['presentation']['flash_green']['timestamps'])[1:][1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Importing useful packages\n",
    "The basic python things are useful, but we will probably need to import some packages to do any kind of data analysis. For most science, numpy and matplotlib (or packages that use matplotlib) are a good place to start. For many \"data science\" applications and some forms of analysis, pandas is also a very useful package. seaborn goes well with pandas, especially for making \"big data\" plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use numpy, an extensive package of quantitative tools (**num**erical **py**thon)\n",
    "<br>**As with all packages (and objects), you access attributes of the package with the ```.``` notation. The ```.``` means you are \"going in something\", to get an attribute or function that lives inside of it**\n",
    "<br>So with that ```import numpy as np``` statement above, we have brought the numpy package and all of its attributes into our notebook. if we want to use a numpy function, we use ```np.name_of_numpy_function_we_want```. For example, numpy has a function called ```save```, which saves a thing to disk. You would use this by typing ```np.save(thing_to_save)```. similarly, the numpy ```load``` function is invoked with ```np.load(thing_to_load)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "packages also have non-function attributes - strings and floats or whatever else. for example, numpy has pi as an attribute, since one sometimes wants pi, to, you know, do numerical calculation type things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>The most important thing is the new variable type: the numpy ndarray. an ndarray is an n-dimensional group of numbers. Here are example one, two, and three dimensional ndarrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_dim = np.array([1,2,3])\n",
    "two_dim = np.array([[1,2,3,4,5],[1,2,3,4,5]])\n",
    "3_dim = np.array([[[1,2,3],[1,2,3],[1,2,3]],[[1,2,3],[1,2,3],[1,2,3]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, here we've done something wrong, and python has given us an error after it tried to do the wrong thing we told it to do. in this case, we tried to name a variabile with an integer at the beginning. that's not allowed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_dim = np.array([[[1,2,3],[1,2,3],[1,2,3]],[[1,2,3],[1,2,3],[1,2,3]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### note: these ```ndarray```s are basically lists of numbers. \n",
    "but, of course, that is the core of what we are doing with *any* kind of quantitative analyusis. ```numpy``` has many, many functions to manipulate and do analysis on them. and numpy ```ndarray```s are much faster than pure python lists. ```scipy``` has many other anaylses, and expects ```numpy``` ```ndarray```s as input. Machine learning packages like ```scikit-learn```, ```tensorflow```, etc. will also often expect numpy, be faster with them, or at least be compatible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>lets work on this time series analysis, using numpy to work with lists of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  11.21952   11.87352   11.89032 ... 2581.27128 2581.88588 2583.94076]\n"
     ]
    }
   ],
   "source": [
    "print(spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q1: What is the first spike time in this list?** \n",
    "<br>i know you can read it off the previous printed list, but print it after indexing a numpy array. if you want, google it, or chatGPT it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q2: What is the sixth spike time in this list?** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow control\n",
    "The next key is being to able to get the computer to do a bunch of these types of things, _programatically_. we can you a `for` loop to something, anything, over each time we go through the loop. here is a toy example of how a `for` loop works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_item in [a, 'list', 0, 'or anything that you can enumerate, or count']:\n",
    "    #do something with each item\n",
    "    print(each_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q3: loop over `dark_stimulus_times`, and print each stimulus time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we know a little bit about how to work with some lists of numbers, and we can start analyzing them. you can do most everything with simple flow control, indexing, and intuituve operations. but sometimes it is easier to use helper function in packages, including in `numpy`. let's use `numpy.where` to find the spikes in `spike_times` that occur after the first time in `dark_stimulus_times`. google `numpy.where` if you need to.\n",
    "# **Q4. what `spike_times` occurred after the first time in `dark_stimulus_times` but before the second?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we're going to get a little more ambitious with the question, leaving it more open-ended. \n",
    "# **Q5: for each dark stimulus time, find the spike times after the stimulus, but before the next stimulus...relative to that stimulus time.**\n",
    " that is, if a stimulus happened at time 23.3 seconds, and a spike at time 23.54, you should note that spike as 0.24 seconds (23.54 - 23.3). again, do this for all spikes each a stimulus time, but before the next stimulus time.<br>\n",
    " this is going to require combining the approaches from **Q3** and **Q4**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's move on to plotting some things. follow along for a few cells before getting back to questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matplotib\n",
    "an extensive package of plotting tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, make some numpy nd arrays to plot. these are going to be:\n",
    "- ```x```: a 1D array increasing from 1.0 to 30.0, over 1000 data points\n",
    "- ```y```: a 1D array of a the sin(x), over 1000 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1,30,1000)\n",
    "y = np.sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can plot what ```x``` and ```y``` look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)\n",
    "plt.xlabel('x data')\n",
    "plt.ylabel('y data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and do some simple calculations on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean: '+str(np.mean(y)))\n",
    "print('s.d.: '+str(np.std(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also do more complicated measurements, like finding the area between two parts of a curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)\n",
    "plt.axhline(np.mean(y),color='red')\n",
    "plt.axhline(np.std(y),color='pink');plt.axhline(np.std(y)*-1,color='pink')\n",
    "plt.xlabel('x data')\n",
    "plt.ylabel('y data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question: in what ranges of x is y above the s.d. of y?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.where(y>np.std(y))[0]\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)\n",
    "\n",
    "plt.axhline(np.mean(y),color='red')\n",
    "plt.axhline(np.std(y),color='pink')\n",
    "plt.axhline(np.std(y)*-1,color='pink')\n",
    "\n",
    "plt.fill_between(x[indices], y[indices], np.std(y),color='pink')\n",
    "\n",
    "plt.xlabel('x data')\n",
    "plt.ylabel('y data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q6: plot all of the relative spike times from Q5**\n",
    "where time is on the x-axis, and each trial is plotted in its own line of the y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is often called a \"raster plot\", and captures the trial-to-trial activity of a neuron relative to some alignment \"time zero\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q7: use matplotlib to plot a histogram of those relative spike times from Q5**\n",
    "again, you can always google/chatGPT `matplotlib histogram`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q8: copying and pasting from above, and changing what you need to, plot a histogram of relative spike times for `bright_stimulus_times`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you want to get fancy, plot the bright and dark histograms as lines, and make the `dark_stimulus_times` black and `bright_stimulus_times` green on your plot, to compare how this cell responds to the two types of stimuli. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other useful packages\n",
    "## Pandas\n",
    "The core data structure in ```pandas``` is a ```DataFrame```.<br>\n",
    "A ```DataFrame``` is essentially a nice table - you could think of it like Excel with simpler indexing and the ability to make any kind of plot your heart desires. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a DataFrame, where the rows are each trial and columns are anything you want for that trial. you could for example get the peak spike count in any 50 msec time window within 1 second of each stimulus, for our example cell, and store this value in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you do this for all `bright_stimulust_times` trials, also do it for all `dark_stimulus_times` trials, and add your counts to the same DataFrame. in this case, you'll also want to add a column to note if this trial was a `bright` or `dark`. call this column `stimulus_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stimulus_type'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seaborn\n",
    "for easy/pretty plotting with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stimulus_type is bright or dark. \n",
    "sns.lineplot(data=df,x='trial',y='max_count',hue='stimulus_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df,x='trial',y='max_count',hue='stimulus_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
